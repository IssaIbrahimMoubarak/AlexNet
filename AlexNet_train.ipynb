{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eispJBJUKmjG"
   },
   "source": [
    "## Hello everybody üòÉ üòÉ welcome back\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ysLDm91jNg-c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Image Size\n",
    "IMG_ROWS, IMG_COLS = 100, 100 # input image dimensions\n",
    "NB_CLASSES =  3 # number of outputs = number of digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pIdma5T4WSnW"
   },
   "source": [
    "## (01)   ACQUISITION DES DONNEES - IMAGES DES FEUILLES DES PLANTES. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SvgdwdQCZFLa"
   },
   "outputs": [],
   "source": [
    "########################################### function for plotting images\n",
    "\n",
    "def plot_images(images, total_images=100, rows=20, cols=5, fsize=(20,100), titre='Image'):\n",
    "    \n",
    "    fig = plt.figure(figsize=fsize) # create a new figure window\n",
    "    \n",
    "    for i in range(total_images): # display images\n",
    "        # subplot : 33 rows and 5 columns\n",
    "        img_grid = fig.add_subplot(rows, cols, i+1)\n",
    "        # plot features as image\n",
    "        img_grid.imshow(images[i])\n",
    "        \n",
    "        plt.title(titre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bAJ4GmbT72p0"
   },
   "outputs": [],
   "source": [
    "############################################ function for resizng images\n",
    "       \n",
    "def preprocess_image(image, image_height=IMG_ROWS, image_width=IMG_COLS):\n",
    "\n",
    "    return cv2.resize(image, (image_height, image_width))\n",
    "\n",
    "############################################ function for reading images \n",
    "       \n",
    "def read_images (path , sz= None ):\n",
    "    \n",
    "    print('\\nCHARGEMENT DES IMAGES DE LA BASE .......................!\\n') \n",
    "\n",
    "    X,y = [], []\n",
    "    \n",
    "    for dirname , dirnames , filenames in os.walk(path):\n",
    "        \n",
    "        c = 0\n",
    "        \n",
    "        for subdirname in dirnames :\n",
    "            \n",
    "            subject_path = os. path . join ( dirname , subdirname )\n",
    "            \n",
    "            for filename in os. listdir ( subject_path ):\n",
    "                \n",
    "                im = Image.open(os.path.join(subject_path, filename))\n",
    "                #im = im.convert (\"L\")\n",
    "\n",
    "                if (sz is not None ):\n",
    "                    im = im.resize (sz , Image.ANTIALIAS ) \n",
    "                    \n",
    "                im = np.array(im)\n",
    "                im = preprocess_image(im, IMG_ROWS, IMG_COLS)\n",
    "                X.append(im)\n",
    "                y.append (c)  \n",
    "                \n",
    "            c = c+1\n",
    "            \n",
    "    return [X,y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ Read And Resize test images\n",
    "\n",
    "print('\\n\\nLECTURE DES IMAGES DE LA BASE D\\'APPRENTISSAGE........!') \n",
    "\n",
    "[X_train, y_train] = read_images(\"C:/Users/Dell 7280/Documents/Etude/ESCEP/S3/Deep learning/Corrections/TP3-Patato/Data/Potato/TrainData\") # Potato\n",
    "\n",
    "print('\\nAFFICHAGE DE QUELQUES IMAGES DE LA BASE.................!')\n",
    "plot_images(X_train, 2, 1, 2,(10, 50), titre='Base D\\'Apprentissage')\n",
    "plt.show()\n",
    "print('\\nFIN D\\'AFFICHAGE DES IMAGES DE LA BASE...................!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################# Train Data\n",
    "\n",
    "images_train = X_train\n",
    "images_train = np.asarray(images_train)\n",
    "\n",
    "# Train targets\n",
    "train_features = images_train\n",
    "train_targets = y_train \n",
    "\n",
    "from keras.utils import to_categorical \n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "train_targets = to_categorical(train_targets, NB_CLASSES)\n",
    "\n",
    "print('\\nNORMALISATION DES BASES DE TEST ET D\\'APPRENTISSAGE.\\n')\n",
    "\n",
    "########################################################## Normalisation\n",
    "\n",
    "train_features = train_features.astype('float32')\n",
    "\n",
    "mean_vals = np.mean(train_features, axis=0)\n",
    "std_val = np.std(train_features)\n",
    "train_features = (train_features - mean_vals)/std_val\n",
    "\n",
    "train_features = train_features.reshape(train_features.shape[0], IMG_ROWS, IMG_COLS, 3)\n",
    "print(\"train_features.shape     >==============<> : {}\".format(train_features.shape))\n",
    "print(\"train_targets.shape      >==============<> : {}\".format(train_targets.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "#(02)        CLASSIFICATION : CREATION DU MODELE DE PREDICTION         #\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from time import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################## Build The Model\n",
    "\n",
    "class AlexNet:\n",
    "    \n",
    "\t@staticmethod\n",
    "\tdef build(input_shape, classes): \n",
    "        \n",
    "\t\tmodel = Sequential() \n",
    "        \n",
    "        # Add the 1st convolution layer (filters = 96, kernel size=11*11, stride=4)\n",
    "\t\tmodel.add(Conv2D(filters = 96, kernel_size=(11,11) , strides=(4, 4), padding=\"same\", input_shape=input_shape))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\t# Max pooling\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\"))\n",
    "\n",
    "        # Add the 2nd convolution layer (filters = 256, kernel size=5*5, stride=1)\n",
    "\t\tmodel.add(Conv2D(filters = 96, kernel_size=(11,11) , strides=(4, 4), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\t# Max pooling\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\"))\n",
    "\n",
    "        # Add the 3rd convolution layer (filters = 384, kernel size=3*3, stride=1)\n",
    "\t\tmodel.add(Conv2D(filters = 384, kernel_size=(3,3), strides=(3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\t\n",
    "\t\t# Add the 4th convolution layer (filters = 384, kernel size=3*3, stride=1)\n",
    "\t\tmodel.add(Conv2D(filters = 384, kernel_size=(3,3), strides=(4, 4), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\t\n",
    "\t\t# Add the 5th convolution layer (filters = 256, kernel size=3*3, stride=1)\n",
    "\t\tmodel.add(Conv2D(filters = 256, kernel_size=(11,11), strides=(1, 1), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\t# Max pooling\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\"))\n",
    "\t\t\n",
    "        # Passing it to a fully Connected Layer FC, Here we do flatten!\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\t\n",
    "        # 1st Fully Connected Layer has 4096 neurons\n",
    "\t\tmodel.add(Dense(4096, input_shape=input_shape))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "        \n",
    "        # Add Dropout to prevent overfitting\n",
    "\t\tmodel.add(Dropout(0.4))\n",
    "        \n",
    "        # 2nd Fully Connected Layer has 4096 neurons\n",
    "\t\tmodel.add(Dense(4096))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "        \n",
    "        # Add Dropout\n",
    "\t\tmodel.add(Dropout(0.4))\n",
    "        \n",
    "        # Add a tanh activation function\n",
    "\t\tmodel.add(Dense(classes))\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "\t\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################## Use The Model\n",
    "\n",
    "# D√©finition de l'optimiseur pour la compilation du mod√®le\n",
    "OPTIMIZER = optimizers.Adam()\n",
    "\n",
    "# D√©finition de la forme d'entr√©e des images pour le mod√®le (hauteur, largeur, nombre de canaux de couleur)\n",
    "INPUT_SHAPE = (IMG_ROWS, IMG_COLS, 3)\n",
    "\n",
    "# D√©finition du nombre d'√©poques (cycles d'entra√Ænement complets sur le dataset)\n",
    "NB_EPOCH = 10\n",
    "\n",
    "# D√©finition de la taille du lot (nombre d'√©chantillons par mise √† jour de gradient)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# D√©finition du niveau de verbosit√© (affichage des informations durant l'entra√Ænement)\n",
    "VERBOSE = 1\n",
    "\n",
    "# Initialisation du mod√®le en utilisant l'architecture AlexNet avec la forme d'entr√©e et le nombre de classes\n",
    "model = AlexNet.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
    "\n",
    "# Compilation du mod√®le avec l'optimiseur 'adam', la fonction de perte 'categorical_crossentropy', et l'√©valuation de la pr√©cision\n",
    "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Affichage d'un r√©sum√© de la structure du mod√®le\n",
    "model.summary()\n",
    "\n",
    "# Enregistrement du temps de d√©but de l'entra√Ænement\n",
    "t_start = time()\n",
    "\n",
    "# Entra√Ænement du mod√®le avec les donn√©es d'entra√Ænement (caract√©ristiques et cibles), en utilisant la taille de lot et le nombre d'√©poques d√©finis\n",
    "history = model.fit(train_features, train_targets, batch_size=BATCH_SIZE, epochs=NB_EPOCH, verbose=VERBOSE)\n",
    "\n",
    "# Calcul du temps total d'entra√Ænement\n",
    "time_full_train = time() - t_start\n",
    "\n",
    "# Affichage du temps d'entra√Ænement du classificateur\n",
    "print(\"\\nTEMPS D'APPRENTISSAGE DU CLASSIFIEUR >====<> : %0.2fs \" % (time_full_train))\n",
    "\n",
    "# Sauvegarde du mod√®le entra√Æn√© dans un fichier\n",
    "model.save(\"AlexNet_groupe_2.h5\")\n",
    "\n",
    "# Affichage d'un message indiquant que le mod√®le a √©t√© enregistr√©\n",
    "print('\\nENREGISTRER LE MODELE .\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure of AlexNet for one dataset patato\n",
    "1.  95.02%\n",
    "2.  95.26%\n",
    "3.  96.95%\n",
    "4.  96.88%\n",
    "5.  96.88%\n",
    "6.  95.42%\n",
    "7.  97.26%\n",
    "8.  96.42%\n",
    "9.  96.79%\n",
    "10. 96.49%\n",
    "\n",
    "\n",
    "Result of AlexNet for ten test = 96.43 %"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
